{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36a09d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from pickle import load\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a0cc3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_doc(filename):\n",
    "    file = open(filename, 'r', encoding='utf-8')\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e6e0ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_seq(model, tokenizer, seq_length, seed_text, n_words):\n",
    "    result = list()\n",
    "    in_text = seed_text\n",
    "    for _ in range(n_words):\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "#         yhat = model.predict_classes(encoded, verbose=0)\n",
    "        predict_x=model.predict(encoded,verbose=0) \n",
    "        yhat=np.argmax(predict_x,axis=1)\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        in_text += ' ' + out_word\n",
    "        result.append(out_word)\n",
    "    return ' '.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4fb2e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have so much difficulty in making myself apprehended like a bad speaker therefore i will not take the whole of the subject but will break a piece off in illustration of my meaning you know the first lines of the iliad in which the poet says that chryses prayed agamemnon\n",
      "\n",
      "disorder to prevent a little conversation at us but what numbers is to be told that the just man is changed by their impulses and tolls which he was acting firmly and unrighteous manifestly their followers to the foundation of the state but what i said is not the cause\n"
     ]
    }
   ],
   "source": [
    "# load cleaned text sequences\n",
    "in_filename = 'republic_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')\n",
    "seq_length = len(lines[0].split()) - 1\n",
    " \n",
    "# load the model\n",
    "model = load_model('model_republic.h5')\n",
    " \n",
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer_republic.pkl', 'rb'))\n",
    " \n",
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')\n",
    " \n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 50)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcd350fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he told me that the best way the state could \n",
      "\n",
      "be supposed to have a special sense which we have been yet to be gentle than the passionate and hindering out of incense and sensuality neither even the idea of good and evil are required by her affections to the other of all these they will introduce him to women\n"
     ]
    }
   ],
   "source": [
    "# load cleaned text sequences\n",
    "in_filename = 'republic_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')\n",
    "seq_length = len(lines[0].split()) - 1\n",
    " \n",
    "# load the model\n",
    "model = load_model('model_republic.h5')\n",
    " \n",
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer_republic.pkl', 'rb'))\n",
    " \n",
    "# select a seed text\n",
    "seed_text = \"he told me that the best way the state could \"\n",
    "print(seed_text + '\\n')\n",
    " \n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 50)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5b146b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on first shouting found the speckled nest with the instinctive confidence that people who bring good news are never in fault said mrs poyser really forgetting all discipline in this pleasant surprise a good lad why where is in ever such a hole under the hedge i saw it first looking\n",
      "\n",
      "after the greenfinch and he sat up at last and there was no joy in a makeshift manner and his own deed is not the hall day and i have had a great deal of those invaluable labourers as to turn contact with a coat of quarterly provocation sleep throwing\n"
     ]
    }
   ],
   "source": [
    "# load cleaned text sequences\n",
    "in_filename = 'adam_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')\n",
    "seq_length = len(lines[0].split()) - 1\n",
    " \n",
    "# load the model\n",
    "model = load_model('model_adam2.h5')\n",
    " \n",
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer_adam2.pkl', 'rb'))\n",
    " \n",
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')\n",
    " \n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 50)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1b6182b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moby dick they must also have food for their more common daily appetites for even the high lifted and chivalric crusaders of old times were not content to traverse two thousand miles of land to fight for their holy sepulchre without committing burglaries picking pockets and gaining other pious perquisites by\n",
      "\n",
      "the whale died away at the same time earnestly watching with another enviable sort of sharks to splinters or drive them back to the deck and poured itself into the present occasion i saw his own place i quaked to feel foremost in this whale and of distension and being\n"
     ]
    }
   ],
   "source": [
    "# load cleaned text sequences\n",
    "in_filename = 'moby_sequences.txt'\n",
    "doc = load_doc(in_filename)\n",
    "lines = doc.split('\\n')\n",
    "seq_length = len(lines[0].split()) - 1\n",
    " \n",
    "# load the model\n",
    "model = load_model('model_moby.h5')\n",
    " \n",
    "# load the tokenizer\n",
    "tokenizer = load(open('tokenizer_moby.pkl', 'rb'))\n",
    " \n",
    "# select a seed text\n",
    "seed_text = lines[randint(0,len(lines))]\n",
    "print(seed_text + '\\n')\n",
    " \n",
    "# generate new text\n",
    "generated = generate_seq(model, tokenizer, seq_length, seed_text, 50)\n",
    "print(generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc98a0e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
